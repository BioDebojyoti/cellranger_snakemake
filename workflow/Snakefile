# Snakemake pipeline for scRNA-seq data using Cell Ranger and Seurat with Docker containers
import os, sys
import pandas as pd


include: "common.smk"
include: os.path.join("rules", "rule_mkfastq.smk")


# print(list(rules.__dict__.keys()))


# one the below three needs to run depending on the experimental design followed by optional aggregate rule
# include: os.path.join("rules", "rule_count.smk")


include: os.path.join("rules", "rule_count.smk")
include: os.path.join("rules", "rule_vdj.smk")


# include: os.path.join("rules", "rule_multi.smk")

# include: os.path.join("rules", "rule_aggregate.smk")


# print(input_for_cellranger_vdj("here"))
# rules_list = list(rules.__dict__.keys())  # list(workflow.__dict__.keys())
# for k in rules_list:
#     print(k + getattr())
# print(getattr(workflow, k))


# rule all:
#     input:
#         expand(
#             "{vdj_outdir}/{sample}_vdj/outs/metrics_summary.csv",
#             sample=list(vdj_fastq_dict.keys()),
#             vdj_outdir=vdj_outdir,
#         ),

# print(rules.cellranger_mkfastq.params.lib_type)


# rule collect_count_results:
#     input:
#         aggr_input_csv=expand(
#             "{count_outdir}/aggregation_count.csv", count_outdir=count_outdir
#         ),


# print(
#     expand(
#         "{fastq_outdirectory}/mkfastq_success_{bcl_run_index}.csv",
#         zip,
#         fastq_outdirectory=list(fastq_outdirectory_dict.values()),
#         bcl_run_index=list(fastq_outdirectory_dict.keys()),
#     ),
# )

# print(
#     expand(
#         "{fastq_outdirectory}/mkfastq_success_{bcl_run_index}.csv",
#         zip,
#         fastq_outdirectory=list(fastq_outdirectory_dict.values()),
#         bcl_run_index=list(fastq_outdirectory_dict.keys()),
#     ),
# )


# Define rules


rule aggr_all:
    input:
        aggr_count_input_csv=expand(
            "{count_outdir}/aggregation_count.csv", count_outdir=count_outdir
        ),
        aggr_vdj_input_csv=expand(
            "{vdj_outdir}/aggregation_vdj.csv", vdj_outdir=vdj_outdir
        ),


rule demultiplex:
    input:
        fastq_paths=expand(
            "{fastq_outdirectory}/mkfastq_success_{bcl_run_index}.csv",
            zip,
            fastq_outdirectory=list(fastq_outdirectory_dict.values()),
            bcl_run_index=list(fastq_outdirectory_dict.keys()),
        ),


# flag = (os.path.join(outdir, "mkfastq.sucess.csv"),)
# aggr_h5 = (
#     (
#         expand(
#             "{count_outdir}/aggr_results/outs/count/filtered_feature_bc_matrix.h5",
#             count_outdir=count_outdir,
#         ),
#     ),
# )
# rule cellranger_count_b4all:
#     output:
#         aggr_input_csv=expand(
#             "{count_outdir}/aggregation_count.csv", count_outdir=count_outdir
#         ),
#     input:
#         flag=os.path.join(outdir, "mkfastq.sucess.csv"),
#         count_info_h5=expand(
#             "{count_outdir}/{sample}_count/outs/molecule_info.h5",
#             sample=list(fastq_dict.keys()),
#             count_outdir=count_outdir,
#         ),
#     params:
#         countdir=count_outdir,
#     shell:
#         """bash scripts/get_aggr_csv.sh {params.countdir} > {params.countdir}/aggregation_count.csv"""
# include: os.path.join("rules","rule_aggregate.smk")
